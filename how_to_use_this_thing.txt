Step 1: You need a bunch of star files. Also, we sort through to find things at roughly ambient temperature and physiological pH.
python download_star_files.py --input_file CNH_withPDB_smallTest.txt --output_dir test_downloaded_files
python filter_and_move_star_files.py --input_dir test_downloaded_files --output_dir test_filtered_files --report_csv test_filtering_report.csv
Note that though some filtering is done here, we need to do more in the next step too.

Step 2: Extract the sequences from them. Also extract the amide hydrogen shifts (will use later).
This script gets the sequences (from a folder full of star files):
extract_sequence_from_str_batch_no_dimers.py
This gets the shifts (it points to a single star file, I'll make it work in batch later):
python scripts/extract_H_shifts_from_str.py star_files/bmr11103_3.str h_shifts/bmr11103_3_H.csv

Step 3: Run AlphaFlow using the sequences. This needs to be done on my desktop with Cameron's modified AlphaFlow.
Here's the useful command for aligning alphaflow output for visualization btw:
cmd.intra_fit("sele", 1)

Step 4: Prep the AlphaFlow PDBs for use. This involves separating the models, adding hydrogens, and fixing the C terminus (it's missing OXT).
add_h_with_cleaning.py is the script for this
Command example:
python ../scripts/add_h_with_cleaning.py bmr34887_3.str.pdb split_models_h
You need to run this while in the pbd_files directory because of the dumb way I wrote the file names.

Step 5: Extract nearest neighbors for all amide hydrogens, then extract distance feature and normalize vectors. This script does that:
python run_extract_batch.py

Step 6: Construct the modified direction vector and put output into format for eventual training. This line does that:
python scripts/concat_neighbors_after_norm_from_all_models_and_sort_and_average_models.py cvs_files/bmr11103_3_rotated cvs_files/bmr11103_3_rotated/bmr11103_3_allNeighborsAllModels_averagedVectors_only25.csv cvs_files/bmr11103_3_rotated/bmr11103_3_allNeighborsAllModels_averagedVectors_only25_groupedFeatures.csv
Note that this makes 2 CSV files. The first is for inspection to assure function, the second is for further processing.

Step 7: Now we go back to those extracted H shifts. We read them in, and for every shift you find, grab the feature vector from the appropriate row of the CSV made in the last step. That can be done like this:
python scripts/attach_shifts_to_features.py h_shifts/bmr11103_3_H.csv cvs_files/bmr11103_3_rotated/bmr11103_3_allNeighborsAllModels_averagedVectors_only25_groupedFeatures.csv training_data/bmr11103_forTraining.csv

Step 8:
On recommendation from Juan and Jon, I'm switching the atom type and residue type to be one-hot encoded. Run with this:
python scripts/one_hot_encode_features.py training_data/bmr11103_forTraining.csv training_data/bmr11103_forTraining_oneHot.csv

